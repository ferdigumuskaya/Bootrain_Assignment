{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue>Assignment</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you are going to measure the performance of the model you created with the Titanic dataset in the previous lesson. To complete this assignment, send a link to a Jupyter notebook containing solutions to the following tasks.\n",
    "\n",
    "- Evaluate your model's performance with cross validation and using different metrics.\n",
    "- Determine the model with the most appropriate parameters by hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_validate,GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic=pd.read_csv('titanic.csv')\n",
    "titanic.drop(columns='Unnamed: 0',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 16 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          891 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        891 non-null    object \n",
      " 11  Embarked     891 non-null    object \n",
      " 12  is_male      891 non-null    int64  \n",
      " 13  Embarked_ID  891 non-null    int64  \n",
      " 14  Cabin_ID     891 non-null    int64  \n",
      " 15  Ticket_ID    891 non-null    int64  \n",
      "dtypes: float64(2), int64(9), object(5)\n",
      "memory usage: 111.5+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target variable\n",
    "Y=titanic.Survived\n",
    "\n",
    "#independent variables\n",
    "X=titanic.iloc[:,[0,2,5,6,7,9,12,13,14,15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=1111,stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dataset isnot imbalanced. I am going to apply cross validation technique which make the model more efficient with optimal C value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549\n",
      "342\n"
     ]
    }
   ],
   "source": [
    "print(titanic[titanic.Survived==0].shape[0])\n",
    "print(titanic[titanic.Survived==1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg=LogisticRegression(multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cross- validation by using `cross_validate()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=cross_validate(estimator=log_reg,X=X_train,y=y_train,cv=3,return_train_score=True,\n",
    "                  scoring=['accuracy','precision','recall','r2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Mean Accuracy  : 0.80  \n",
      "Train Set Mean R-square  : 0.15  \n",
      "Train Set Mean Precision : 0.78 \n",
      "Train Set Mean Recall    : 0.66\n",
      "\n",
      "Test Set Mean Accuracy   : 0.79  \n",
      "Test Set Mean R-square   : 0.13  \n",
      "Test Set Mean Precision  : 0.78  \n",
      "Test Set Mean Recall     : 0.65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Train Set Mean Accuracy  : {:.2f}  '.format(cv['train_accuracy'].mean()))\n",
    "print('Train Set Mean R-square  : {:.2f}  '.format(cv['train_r2'].mean()))\n",
    "print('Train Set Mean Precision : {:.2f} '.format(cv['train_precision'].mean()))\n",
    "print('Train Set Mean Recall    : {:.2f}\\n'.format(cv['train_recall'].mean()))\n",
    " \n",
    "print('Test Set Mean Accuracy   : {:.2f}  '.format(cv['test_accuracy'].mean()))\n",
    "print('Test Set Mean R-square   : {:.2f}  '.format(cv['test_r2'].mean()))\n",
    "print('Test Set Mean Precision  : {:.2f}  '.format(cv['test_precision'].mean()))\n",
    "print('Test Set Mean Recall     : {:.2f}\\n'.format(cv['test_recall'].mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={'C': [10**x for x in range(-5,5,1)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv=GridSearchCV(estimator=log_reg, \n",
    "                     param_grid=parameters,\n",
    "                     cv=5,\n",
    "                     return_train_score=True,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(multi_class='ovr'),\n",
       "             param_grid={'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100,\n",
       "                               1000, 10000]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters :  {'C': 10}\n",
      "Best Score      :  0.7977937555402344\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters : \", grid_cv.best_params_)\n",
    "print(\"Best Score      : \", grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0.797794</td>\n",
       "      <td>0.803376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>0.796395</td>\n",
       "      <td>0.801266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.794997</td>\n",
       "      <td>0.794948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.794997</td>\n",
       "      <td>0.803725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.790761</td>\n",
       "      <td>0.802671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.779533</td>\n",
       "      <td>0.790034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.737339</td>\n",
       "      <td>0.744374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.709189</td>\n",
       "      <td>0.714181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.700758</td>\n",
       "      <td>0.705050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.695154</td>\n",
       "      <td>0.698378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C  mean_test_score  mean_train_score\n",
       "6      10         0.797794          0.803376\n",
       "7     100         0.796395          0.801266\n",
       "9   10000         0.794997          0.794948\n",
       "8    1000         0.794997          0.803725\n",
       "5       1         0.790761          0.802671\n",
       "4     0.1         0.779533          0.790034\n",
       "3    0.01         0.737339          0.744374\n",
       "2   0.001         0.709189          0.714181\n",
       "1  0.0001         0.700758          0.705050\n",
       "0   1e-05         0.695154          0.698378"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = grid_cv.cv_results_\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df = df[['param_C', 'mean_test_score','mean_train_score']]\n",
    "df = df.sort_values(by='mean_test_score', ascending = False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hyperparameters can be set to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg1=LogisticRegression(C=10,multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, multi_class='ovr')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds=log_reg1.predict(X_train)\n",
    "test_preds=log_reg1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr=classification_report(y_test,test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82       110\n",
      "           1       0.76      0.55      0.64        69\n",
      "\n",
      "    accuracy                           0.76       179\n",
      "   macro avg       0.76      0.72      0.73       179\n",
      "weighted avg       0.76      0.76      0.75       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
