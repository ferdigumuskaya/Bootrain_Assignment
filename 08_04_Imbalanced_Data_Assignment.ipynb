{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue>Assignment</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the [dataset](https://sci2s.ugr.es/keel/dataset/data/imbalanced/cleveland-0_vs_4.zip) for the [risk of heart attack](https://sci2s.ugr.es/keel/dataset.php?cod=980) with class imbalance:\n",
    "\n",
    "1. Create a logistic regression model and measure the performance of it.\n",
    "2. By experimenting with different methods and class ratios; overcome class imbalance, determine the best performing method and class ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,accuracy_score,recall_score,precision_score,f1_score,confusion_matrix,roc_curve, roc_auc_score,precision_recall_curve\n",
    "from sklearn.utils import resample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Data Cleaning & Convert the object to categorical ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "ha_df=pd.read_csv('the_risk_heart_attack.dat', header='infer',sep=',', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "ha_df.loc[[44],['thal']]='3.0'\n",
    "ha_df.loc[[85,146],['ca']]='0.0'\n",
    "ha_df.loc[[142],['ca']]='1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "ha_df.ca=ha_df.ca.astype('float')\n",
    "ha_df.thal=ha_df.thal.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "ha_df['is_risk']=pd.get_dummies(data=ha_df.num,drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y= ha_df['is_risk']\n",
    "\n",
    "X= ha_df.iloc[:,0:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of having no risk of heart attack is 164 \n",
      "The number of having risk of heart attack is 13\n"
     ]
    }
   ],
   "source": [
    "print('The number of having no risk of heart attack is {} '.format(ha_df[ha_df.is_risk==0].shape[0]))\n",
    "print('The number of having risk of heart attack is {}'.format(ha_df[ha_df.is_risk==1].shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the light of above the Output, the Dataset is obviously imbalanced. while the number of having risk of heart attack is 13, the number of having no risk of heart attack is 164. I am going to, at first, apply logistic regression in this dataset and notably examine the recall score of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_values(X,Y):\n",
    "\n",
    "    C_values = [0.001,0.01, 0.1,1,10,100, 1000]\n",
    "    X_train, X_test, y_train, y_test =  train_test_split(X, Y, test_size=0.20, random_state=111, stratify = Y)\n",
    "    accuracy_values = pd.DataFrame(columns=['C_values', 'Train Accuracy', 'Test Accuracy'])\n",
    "\n",
    "    for c in C_values:\n",
    "    # Apply logistic regression model to training data\n",
    "        lr = LogisticRegression(penalty = 'l2', C = c, random_state = 0, solver='lbfgs', multi_class='ovr')\n",
    "        lr.fit(X_train, y_train)\n",
    "        accuracy_values = accuracy_values.append({'C_values': c,\n",
    "                                                'Train Accuracy': lr.score(X_train, y_train),\n",
    "                                                'Test Accuracy': lr.score(X_test, y_test)\n",
    "                                                }, ignore_index=True)\n",
    "    display(accuracy_values) \n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C=1 is better penalty score compared to the other ones, which expresses the data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test= train_test_split(X,Y,test_size=0.2,stratify=Y,random_state=1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg=LogisticRegression(C=1.0,solver='lbfgs',multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='ovr', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_train=log_reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds=log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of Train is 0.9858156028368794\n",
      "The accuracy score of Test is 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "train_accuracy= accuracy_score(y_train,y_preds_train)\n",
    "test_accuracy= accuracy_score(y_test,y_preds)\n",
    "print('The accuracy score of Train is {}'.format(train_accuracy))\n",
    "print('The accuracy score of Test is {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        33\n",
      "           1       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.82      0.82      0.82        36\n",
      "weighted avg       0.94      0.94      0.94        36\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       131\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.99       141\n",
      "   macro avg       0.99      0.90      0.94       141\n",
      "weighted avg       0.99      0.99      0.99       141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_preds))\n",
    "print(classification_report(y_train,y_preds_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of having imbalanced dataset, Recall and Precision scores are drastically different in the Train and Test Dataset. I am going to solve this problem, then applying model to new dataset could be meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X, y,c):\n",
    "    X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.20, random_state=111, stratify = y)\n",
    "    \n",
    "    logreg_model = LogisticRegression(C=c)\n",
    "    logreg_model.fit(X_train, y_train)\n",
    "\n",
    "    pred_train = logreg_model.predict(X_train)\n",
    "    pred_test = logreg_model.predict(X_test)\n",
    "    \n",
    "    conf_mtx_train = confusion_matrix(y_train, pred_train)\n",
    "    conf_mtx_test = confusion_matrix(y_test, pred_test)\n",
    "    \n",
    "    print(\"Accuracy : {}\\n\".format(logreg_model.score(X_test, y_test)))\n",
    "    \n",
    "    print(\"Train Dataset\")\n",
    "    print(classification_report(y_train, pred_train))\n",
    "    \n",
    "    print(\"Test Dataset\")\n",
    "    print(classification_report(y_test, pred_test))\n",
    "    \n",
    "    return  None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to try to apply Up-Sampling method compared to SMOTE and ADAYNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_risk_data=ha_df[ha_df.is_risk==0]\n",
    "risky_data=ha_df[ha_df.is_risk==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "risky_data_upsampling=resample(risky_data,replace=True,n_samples=len(no_risk_data),random_state=1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_sampled_ha=pd.concat([no_risk_data,risky_data_upsampling])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=up_sampled_ha['is_risk']\n",
    "\n",
    "X=up_sampled_ha.iloc[:,:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_values</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.805344</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.896947</td>\n",
       "      <td>0.893939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.958015</td>\n",
       "      <td>0.939394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.969466</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.980916</td>\n",
       "      <td>0.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.984733</td>\n",
       "      <td>0.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000.000</td>\n",
       "      <td>0.984733</td>\n",
       "      <td>0.969697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_values  Train Accuracy  Test Accuracy\n",
       "0     0.001        0.805344       0.772727\n",
       "1     0.010        0.896947       0.893939\n",
       "2     0.100        0.958015       0.939394\n",
       "3     1.000        0.969466       0.954545\n",
       "4    10.000        0.980916       0.969697\n",
       "5   100.000        0.984733       0.969697\n",
       "6  1000.000        0.984733       0.969697"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c_values(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9696969696969697\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       131\n",
      "           1       0.97      1.00      0.98       131\n",
      "\n",
      "    accuracy                           0.98       262\n",
      "   macro avg       0.99      0.98      0.98       262\n",
      "weighted avg       0.99      0.98      0.98       262\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        33\n",
      "           1       0.94      1.00      0.97        33\n",
      "\n",
      "    accuracy                           0.97        66\n",
      "   macro avg       0.97      0.97      0.97        66\n",
      "weighted avg       0.97      0.97      0.97        66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_model(X,Y,c=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
